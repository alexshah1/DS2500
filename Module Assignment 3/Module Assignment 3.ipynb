{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7193f648",
   "metadata": {},
   "source": [
    "# DS 2500: Data Wrangling<br>Module Assignment 3\n",
    "March 1, 2022\n",
    "\n",
    "Student: Alexander Shahramanyan<br>\n",
    "Instructor: Professor Marina Kogan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f04f5148",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "Cryptocurrencies gained significant popularity over the last years and has gathered big communities of traders. In this assignment, I'll use the CoinAPI to get Bitcoin price data and will try to get some insights from it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "845fcf7d",
   "metadata": {},
   "source": [
    "## Questions:\n",
    "1. Is the Bitcoin price data (which is timeseries, of course) stationary (it should be non-stationary, however, I'll use a statistical test to ensure that)?\n",
    "2. Are number of trades or volume traded correlated with Bitcoin prices? \n",
    "3. Is there a correlation between Covid cases and Bitcoin price?\n",
    "<hr>\n",
    "0 - Is there a significant difference between the Bitcoin prices of any two consecutive weeks as compared to others?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad54f3f8",
   "metadata": {},
   "source": [
    "## Dataset Description:\n",
    "**Dataset 1: Bitcoin Prices**: from CoinAPI. Contains hourly data on Bitcoin prices for 2020: open time, open and close, high and low, prices, volume traded, and trades count.\n",
    "<br>\n",
    "\n",
    "*Columns*:<br>\n",
    "7 columns\n",
    "- time_open - datetime\n",
    "- price_open - float\n",
    "- price_high - float\n",
    "- price_low - float\n",
    "- price_close - float\n",
    "- volume_traded - float\n",
    "- trades_count - int\n",
    "\n",
    "*Number of entries (rows)*: 8759 (366\\*24=8784, however API fails to provide some data)<br><hr>\n",
    "\n",
    "**Dataset 2: Covid Cases**: from John Hopkins University Covid tracking website (via github). Contains daily information on cumulative Covid cases per province/state and country/region.\n",
    "*Columns*:<br>\n",
    " 772 columns\n",
    "- Province/State - string\n",
    "- Country/Region - string\n",
    "- Lat (latitude) - float\n",
    "- Long (longitude) - float\n",
    "- 1/22/20 - int (cumulative Covid cases)\n",
    "- .......\n",
    "- 2/27/22 - int (cumulative Covid cases)\n",
    "\n",
    "*Number of entries (rows)*: 284"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78ad2cee",
   "metadata": {},
   "source": [
    "## Setup\n",
    "First, I import all the libraries I will need throughout the notebook and set the plotting parameters for better visualizations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a9f19356",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "import pandas as pd\n",
    "import time\n",
    "import datetime as dt\n",
    "import json\n",
    "from scipy.stats import stats, pearsonr\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import textwrap\n",
    "\n",
    "# Plotting settings\n",
    "plt.style.use('seaborn')\n",
    "plt.rcParams['figure.figsize'] = (16, 6)\n",
    "plt.rcParams['figure.dpi'] = 150\n",
    "plt.rcParams['font.size'] = 18\n",
    "plt.rcParams['axes.labelsize'] = 16\n",
    "plt.rcParams['axes.titlesize'] = 16\n",
    "plt.rcParams['xtick.labelsize'] = 12\n",
    "plt.rcParams['ytick.labelsize'] = 12\n",
    "plt.rcParams['font.family'] = 'serif'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44505eb2",
   "metadata": {},
   "source": [
    "CoinAPI-Keys:<br>\n",
    " - 7C42C2B0-B30F-4988-9B5C-6F6EE0237D3E  <br>\n",
    " - 49BAD700-37F7-4776-9A80-E95274FE737A  <br>\n",
    " - D6F38463-FC87-4C68-AF3A-FBCC83F2A57D  <br>\n",
    " - E87012DB-899D-41CD-A2D7-CB6510046225  <br>\n",
    " - 1BB08CB1-10A5-44CF-9B48-72245E12F41D  <br>\n",
    " - 831F56DE-37FD-4D77-B4FC-FE72108716A0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8539e326",
   "metadata": {},
   "source": [
    "## Get Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aedd8081",
   "metadata": {},
   "source": [
    "Next, I define a function that gets data from CoinAPI. Since there is a limit on the amount of data that that can be get per request, I will call this function repeatedly in order to get hourly data for a full year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7ee080c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(symbol=\"BINANCE_SPOT_BTC_USDT\", start_date=\"2020-01-01\", end_date=\"2020-12-31\", step=\"1HRS\", convert_date_times=True):\n",
    "    \"\"\"\n",
    "    Gets and returns the price data of the symbol, for the given time interval and frequence.\n",
    "    \n",
    "    Keyword parameters:\n",
    "        symbol            - the symbol whose price data should be downloaded.\n",
    "                           Default: \"BINANCE_SPOT_BTC_USDT\"\n",
    "                \n",
    "        start_date         - the start date.\n",
    "                           Default: \"2020-01-01\"\n",
    "        \n",
    "        end_date           - the end date.\n",
    "                           Default: \"2020-12-31\"\n",
    "        \n",
    "        step               - the frequency of the data.\n",
    "                           Possible values: 1SEC, 2SEC, 3SEC, 4SEC, 5SEC, 6SEC, 10SEC, 15SEC, 20SEC, 30SEC,\n",
    "                                            1MIN, 2MIN, 3MIN, 4MIN, 5MIN, 6MIN, 10MIN, 15MIN, 20MIN, 30MIN,\n",
    "                                            1HRS, 2HRS, 3HRS, 4HRS, 6HRS, 8HRS, 12HRS,\n",
    "                                            1DAY, 2DAY, 3DAY, 5DAY, 7DAY, 10DAY.\n",
    "                           Default: \"1HRS\"\n",
    "            \n",
    "        convert_date_times - if true, will convert the start and end dates from\n",
    "                           'YYYY-MM-DD' into a datetime object, otherwise considers\n",
    "                           the dates are datetimes.\n",
    "                           Default: True\n",
    "    Returns:\n",
    "        A list of json objects witht the price data.\n",
    "    \"\"\"\n",
    "    # Header for the request\n",
    "    headers = {\"X-CoinAPI-Key\" : \"7C42C2B0-B30F-4988-9B5C-6F6EE0237D3E\"}\n",
    "    \n",
    "    # List for the JSON objects\n",
    "    responses = []\n",
    "    \n",
    "    # Convert the start and end dates into datetimes if needed\n",
    "    if convert_date_times:\n",
    "        start_date = dt.datetime.combine(dt.date.fromisoformat(start_date), dt.time(0, 0, 0, 0))\n",
    "        end_date = dt.datetime.combine(dt.date.fromisoformat(end_date), dt.time(23, 59, 0, 0))\n",
    "    \n",
    "    # Convert the end date into the required string format to use in the link\n",
    "    end_date_str = end_date.strftime(\"%Y-%m-%dT%H:%M:%S\")\n",
    "    \n",
    "    if step[-3:] == \"SEC\":\n",
    "        window = dt.timedelta(seconds = int(step[:-3])*100)\n",
    "    elif step[-3:] == \"MIN\":\n",
    "        window = dt.timedelta(minutes = int(step[:-3])*100)\n",
    "    elif step[-3:] == \"HRS\":\n",
    "        window = dt.timedelta(hours = int(step[:-3])*100)\n",
    "    elif step[-3:] == \"DAY\":\n",
    "        window = dt.timedelta(days = int(step[:-3])*100)\n",
    "    else:\n",
    "        raise ValueError(\"Illegal step argument.\")\n",
    "\n",
    "    # While there still is data to download\n",
    "    while start_date <= end_date:\n",
    "        # Convert the current start time into the requiored string format to use in the link\n",
    "        start = start_date.strftime(\"%Y-%m-%dT%H:%M:%S\")\n",
    "        \n",
    "        # Add the windows to the start date\n",
    "        start_date += window\n",
    "        \n",
    "        # Create the url\n",
    "        url = f\"https://rest.coinapi.io/v1/ohlcv/{symbol}/history?period_id={step}&time_start={start}&time_end={end_date_str}\"\n",
    "        \n",
    "        # Send the request and store the response\n",
    "        response = requests.get(url, headers=headers)\n",
    "        \n",
    "        # Not OK API responses\n",
    "        if response.status_code != 200:\n",
    "            if response.status_code == 400:\n",
    "                print(\"Bad Request -- There is something wrong with your request.\")\n",
    "            elif response.status_code == 401:\n",
    "                print(\"Unauthorized -- Your API key is wrong.\")\n",
    "            elif response.status_code == 403:\n",
    "                print(\"Forbidden -- Your API key doesnt't have enough privileges to access this resource.\")\n",
    "            elif response.status_code == 429:\n",
    "                print(\"Too many requests -- You have exceeded your API key rate limits.\")\n",
    "            elif response.status_code == 550:\n",
    "                print(\"No data -- You requested specific single item that we don't have at this moment.\")\n",
    "            \n",
    "            print(\"Exiting function.\")\n",
    "            \n",
    "            return responses\n",
    "        \n",
    "        # Add the JSON objects to the list\n",
    "        responses += response.json()\n",
    "        \n",
    "        # Wait for a second\n",
    "        time.sleep(1)\n",
    "        \n",
    "    return responses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66b62ed1",
   "metadata": {},
   "source": [
    "I will also need to make a dataframe from the JSON objects. For that, I will create another function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "106df866",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_df(responses):\n",
    "    \"\"\"\n",
    "    Creates a dataframe from the JSON objects and return. Converts the time columns into datetime.\n",
    "    \n",
    "    Keyword parameters:\n",
    "        responses - a list with JSON objects.\n",
    "        \n",
    "    Returns:\n",
    "        A dataframe created from the JSON objects.\n",
    "    \"\"\"\n",
    "    # Initialize a dataframe from the responses\n",
    "    df = pd.DataFrame(responses)\n",
    "    \n",
    "    # Change the types of the time columns to datetime\n",
    "    for col in [x for x in df.columns if \"time\" in x]:\n",
    "        df[col] = pd.to_datetime(df[col])\n",
    "    \n",
    "    # Drop duplicates\n",
    "    df.drop_duplicates(inplace=True)\n",
    "    \n",
    "    # Sort the data by time_open\n",
    "    df.sort_values('time_period_start', inplace=True)\n",
    "    \n",
    "    # Reset index\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b609855e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the data\n",
    "responses = get_data(symbol=\"BINANCE_SPOT_BTC_USDT\", start_date=\"2020-01-01\", end_date=\"2020-12-31\",\\\n",
    "                     step=\"1HRS\", convert_date_times=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9631db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataframe from the downloaded data\n",
    "df = to_df(responses)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb7fedba",
   "metadata": {},
   "source": [
    "## Dataset Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45188023",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "# df = pd.read_csv(\"BTCUSDT_2020.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d067ee4f",
   "metadata": {},
   "source": [
    "We should have 366*24 = 8784 rows in the dataframe. I'll check that using df.shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6c0786a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check dataset shape\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71481468",
   "metadata": {},
   "source": [
    "As we see, we have only 8759 rows. There seems to be some error with the CoinAPI, I'll try to get the missing data again. Now, I'll check the top and bottom of the data, to ensure the start and end dates are correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdfff89c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the top of the data\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c12aa96a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the bottom of the data\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "876b99dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the number of rows in the dataframe\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8ede725",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check null values\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca2012fc",
   "metadata": {},
   "source": [
    "I'll only keep only one time data column. The others are unnecessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c281b8dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep only one time data column\n",
    "df = df[['time_period_start', 'price_open', 'price_high', 'price_low',\\\n",
    "         'price_close', 'volume_traded', 'trades_count']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a67370f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename the time data column\n",
    "df.rename(columns = {'time_period_start':'time_open'}, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2ccf5a2",
   "metadata": {},
   "source": [
    "Try to download the missing data again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fca23b5d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Try to download the missing data again using the API\n",
    "for row in range(1, len(df.index)):\n",
    "    # If the difference between two consecutive values is not 1, download the data between \n",
    "    if abs(df.time_open[row] - df.time_open[row-1] - dt.timedelta(hours=1)) > dt.timedelta(minutes=5):\n",
    "        start_date = df.time_open[row-1] + dt.timedelta(hours=1)\n",
    "        end_date = df.time_open[row]\n",
    "        \n",
    "        responses = get_data(start_date=start_date, end_date=end_date, step=\"1HRS\", convert_date_times=False)\n",
    "\n",
    "        # If nothing was returned from the request, continue\n",
    "        if responses == []:\n",
    "            continue\n",
    "        \n",
    "        # Print the JSON objects returned\n",
    "        print(responses)\n",
    "        \n",
    "        # Create a dataframe from the new JSON objects\n",
    "        df_add = to_df(responses)\n",
    "    \n",
    "        df_add = df_add[['time_period_start', 'price_open', 'price_high', 'price_low',\\\n",
    "             'price_close', 'volume_traded', 'trades_count']]\n",
    "        \n",
    "        df_add.rename(columns = {'time_period_start':'time_open'}, inplace = True)\n",
    "\n",
    "        # Append the new data to the dataframe\n",
    "        df = df.append(df_add, ignore_index = True)\n",
    "        \n",
    "# Drop duplicates\n",
    "df.drop_duplicates(inplace=True)\n",
    "    \n",
    "# Sort the data by time_open\n",
    "df.sort_values('time_open', inplace=True)\n",
    "    \n",
    "# Reset index\n",
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87461b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the number of rows in the dataframe\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13f3c402",
   "metadata": {},
   "source": [
    "As we see, no new rows were added. There seems to be some problem with the API. Since only 25 entries are missing, there is no need to worry. I will now plot the priceline (close prices) to see if there is any trend."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa505ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Priceline\n",
    "ax = sns.lineplot(x=\"time_open\", y=\"price_close\", data=df, color='#748B75')\n",
    "\n",
    "# Set y-axis label\n",
    "ax.set_ylabel(\"Price ($)\")\n",
    "\n",
    "# Set x-axis label\n",
    "ax.set_xlabel(\"Date\")\n",
    "\n",
    "# Set x limits\n",
    "ax.set_xlim(df.iloc[0].time_open, df.iloc[-1].time_open)\n",
    "\n",
    "# Set y limits\n",
    "ax.set_ylim(df.price_close.min()*.92, df.price_close.max()*1.08)\n",
    "\n",
    "# Title\n",
    "ax.set_title(\"BTC Price Over Time\")\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26a27487",
   "metadata": {},
   "source": [
    "There is a steady increaseing trend in the close prices over the year."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f36eacce",
   "metadata": {},
   "source": [
    "## Q1: Stationary or Non-Stationary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b6478b7",
   "metadata": {},
   "source": [
    "Here, I'll check if the price data is stationary or not. Stationarity implies that taking consecutive samples of data with the same size should have identical covariances regardless of the starting point. The Bitcoin price is very volatile and has changed significantly and rapidly over time. So it should not be stationary. To check that I'll conduct a Dickey-Fuller Test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d338d710",
   "metadata": {},
   "outputs": [],
   "source": [
    "def adf_test(timeseries):\n",
    "    \"\"\"\n",
    "    Calculates and prints the results of Dickey-Fuller test on the given timeseries.\n",
    "    \n",
    "    Keyword parameters:\n",
    "        timeseries - the timeseries, on which the Dickey-Fuller test should be calculated.\n",
    "    \"\"\"\n",
    "    print ('Results of Dickey-Fuller Test:')\n",
    "    dftest = adfuller(timeseries, autolag='AIC')\n",
    "    dfoutput = pd.Series(dftest[0:4], index=['Test Statistic','p-value','#Lags Used','Number of Observations Used'])\n",
    "    for key,value in dftest[4].items():\n",
    "        dfoutput['Critical Value (%s)'%key] = value\n",
    "    print (dfoutput)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "340e5d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "dftest = adf_test(df['price_close'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a292722",
   "metadata": {},
   "source": [
    "The p-value is greater than 0.05, the timeseries is non-stationary."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "283db414",
   "metadata": {},
   "source": [
    "## Q2: Correlations Between Price and Trades count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "289b13bf",
   "metadata": {},
   "source": [
    "I'll calculate correlation between a couple of variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "136f7811",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "corr, _ = pearsonr(df[\"volume_traded\"], df[\"trades_count\"])\n",
    "print('Pearsons correlation: %.3f' % corr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4a65be5",
   "metadata": {},
   "source": [
    "As we can see, there is a strong correlation between `volume_traded` and `trades_count`. This is quite logical. Now, I'll see if `trades_count` or `volume_traded` is correlated with `price_close`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9ab38e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr, _ = pearsonr(df[\"trades_count\"], df[\"price_close\"])\n",
    "print('Pearsons correlation: %.3f' % corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bbfa246",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr, _ = pearsonr(df[\"volume_traded\"], df[\"price_close\"])\n",
    "print('Pearsons correlation: %.3f' % corr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e611c6a",
   "metadata": {},
   "source": [
    "`trades_count` and `price_close` are correlated (to some extent). This means more trades are done when the close price is high. However, there is no correlation between `volume_traded` and `price_close`, meaning the volume traded is not realted with the close price, even though the higher the close price the more trades are done."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5fce1ff",
   "metadata": {},
   "source": [
    "## Q3: Covid cases and Bitcoin price"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "494b54f4",
   "metadata": {},
   "source": [
    "## Load and Check Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d350355a",
   "metadata": {},
   "source": [
    "Now, I'll try to see if there was any correlation between the covid cases (both daily and cumulative) and Bitcoin price. First, I read the csv file with Covid cases data into a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91d2c0de",
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_df = pd.read_csv(\"https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_global.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "521a3caa",
   "metadata": {},
   "source": [
    "Next, I check the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c1048ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check dataset shape\n",
    "covid_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d11264f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the top of the data\n",
    "covid_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bb0afaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the bottom of the data\n",
    "covid_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "957c8c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the number of rows in the dataframe\n",
    "len(covid_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fa1d643",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check null values\n",
    "covid_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "690993f8",
   "metadata": {},
   "source": [
    "I won't use the `Province/State` column, so no need to impute or drop nulls. Since I will only need the daily Covid cases worldwide for 2020, I will only keep the columns with 2020 data and combine the cases from all countries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bcdd52e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Columns with 2020 data\n",
    "date_cols = [x for x in covid_df.columns if x[-3:] == '/20']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "107fa848",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep the columns with 2020 data\n",
    "covid_df = covid_df[date_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e91a5e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the dataset\n",
    "covid_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21e53cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the column names to datetime objects\n",
    "date_cols = pd.to_datetime(covid_df.columns, format=\"%m/%d/%y\")\n",
    "covid_df.columns = date_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6106de06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the dataset\n",
    "covid_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ded9e9b3",
   "metadata": {},
   "source": [
    "Since I will need the total cumulative cases and new daily cases, I combine the given data per country and store them in a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9f9e7a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the covid cases from all countries\n",
    "covid_cases = pd.DataFrame(covid_df.sum(), columns=['cases'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8186505e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the dataset\n",
    "covid_cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47a23edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a column with daily new cases\n",
    "covid_cases['daily_cases'] = covid_cases.cases - covid_cases.cases.shift(1, fill_value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0798c9d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the dataset\n",
    "covid_cases"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddc27e0b",
   "metadata": {},
   "source": [
    "Then, I need to merge the Bitcoin price and Covid case dataframes. To do so, I'll create a new column in each dataframe with the day of year, to later merge on. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a1b931b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['dayofyear'] = df.time_open.dt.dayofyear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b9aed26",
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_cases['dayofyear'] = covid_cases.index.dayofyear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ed3c2fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge on dayofyear\n",
    "merged_df = pd.merge(df, covid_cases, on='dayofyear').drop('dayofyear', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afbbd160",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the dataset\n",
    "merged_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d9cdba7",
   "metadata": {},
   "source": [
    "Now, I'll plot the Bitcoin prices and # of Covid cases against each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eb0f9cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Price and Covid cases over time\n",
    "ax = sns.lineplot(x=\"time_open\", y=\"price_close\", data=merged_df, color='#FFBC42')\n",
    "ax_sec = ax.twinx()    \n",
    "ax_sec = sns.lineplot(x=\"time_open\", y=\"cases\", data=merged_df, color='#748B75')\n",
    "\n",
    "# Set y-axis label\n",
    "ax.set_ylabel(\"Price ($)\")\n",
    "ax_sec.set_ylabel(\"Cases\")\n",
    "\n",
    "# Set x-axis label\n",
    "ax.set_xlabel(\"Date\")\n",
    "\n",
    "# Title\n",
    "ax.set_title(\"BTC Price and # of Covid Cases Over Time\")\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc6abbd7",
   "metadata": {},
   "source": [
    "There seems to be a correlation between these variables. We can check that by conducting Pearson's correlation test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f9e135e",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr, _ = pearsonr(merged_df.price_close, merged_df.cases)\n",
    "print('Pearsons correlation: %.3f' % corr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01c8874e",
   "metadata": {},
   "source": [
    "The result ensures that there is a strong correlation between the # of cumulative Covid cases and Bitcoin prices. Next, I'll plot the daily new cases agains Bitcoin prices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc39acb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Price and New Daily Covid cases over time\n",
    "ax = sns.lineplot(x=\"time_open\", y=\"price_close\", data=merged_df, color='#FFBC42')\n",
    "ax_sec = ax.twinx()    \n",
    "ax_sec = sns.lineplot(x=\"time_open\", y=\"daily_cases\", data=merged_df, color='#748B75')\n",
    "\n",
    "# Set y-axis label\n",
    "ax.set_ylabel(\"Price ($)\")\n",
    "\n",
    "# Set x-axis label\n",
    "ax.set_xlabel(\"Date\")\n",
    "\n",
    "# Title\n",
    "ax.set_title(\"BTC Price and # of New Covid Cases Over Time\")\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33680ee0",
   "metadata": {},
   "source": [
    "Again, there seems to be a correlation between the two variables, though not as strong as between the last two variables. I'll conduct a Pearson's correlation test to find the correlation coefficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "236824cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr, _ = pearsonr(merged_df.price_close, merged_df.daily_cases)\n",
    "print('Pearsons correlation: %.3f' % corr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c73ca391",
   "metadata": {},
   "source": [
    "As can be seen, there, indeed, is a strong correlation between the new Covid cases and Bitcoin price."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac79684c",
   "metadata": {},
   "source": [
    "## Write-up"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df6b1015",
   "metadata": {},
   "source": [
    "For Module Assignment 3, I have chosen to get the Bitcoin price data for 2020 using the CoinAPI. The dataset contains hourly Bitcoin price data, including open, close, low, and high prices. There is also data on trades count and volume traded. I've chosen 3 questions, that I will try to answer using the data I have. Firstly, I want to assure the time series data of Bitcoin prices is non-stationary, i.e., the means, variances, and covariances change over time. This also means that it is hard to model the data. As many different factors affect Bitcoin price, its market is quite volatile, and there are rapid and significant increases or decreases, I know it should be non-stationary. Secondly, I try to find out if there is a correlation between `volume_traded` or `trades_count` and `price_close` variables. I believe that when the Bitcoin price is high, more trades are done. Nonetheless, I am not really sure about `volume_traded` at high prices. And lastly, I'll try to see if there is a correlation, between Covid cases (both daily new cases and total cumulative cases) and the Bitcoin price (or if there was a correlation in 2020). For the last question, I would need another dataset, which I'll describe in detail as I answer Question 3.\n",
    "\n",
    "It is important to mention that CoinAPI has both a daily limit and a limit on data received by a request, which makes using it (the free version) a bit inconvenient. Thus, I had to send multiple requests and combine the received data. After gathering and combining the data for the whole interval, I found out some rows were missing. I tried requesting these missing values again, however, it turned out the mistake was probably in the API since the request returned an empty list. Nonetheless, out of 8784 entries (24 hours * 366 days), only 25 were missing, which is roughly 0.3% and is negligible even though the data is time series (there were not many consecutive missing values). After collecting the data, I checked it and made sure the interval is correct, checked the top and bottom, and proceeded to Question 1.\n",
    "\n",
    "To find out whether the time series is stationary or non-stationary, I conducted a Dickey-Fuller Test, which uses the following null and alternative hypotheses:\n",
    "- H0: The time series is non-stationary. In other words, it has some time-dependent structure and does not have constant variance over time.\n",
    "- HA: The time series is stationary.\n",
    "If the p-value from the test is less than some significance level (I'll take 0.05), then we can reject the null hypothesis and conclude that the time series is stationary. I performed the test using the `adfuller` function from `statsmodels.tsa.stattools` library. The p-value returned was much higher than 0.05, which means we don't have enough evidence to reject the Null hypothesis, so we accept it, meaning the time series is non-stationary. This lines up with my assumption.\n",
    "\n",
    "Next, I've tried to see if any of `volume_traded` or `trades_count` is correlated with `price_close`. I've tested that using the Pearson correlation test, the `pearsonr` function from the `scipy.stats` library. However, firstly, I calculated the correlation between `volume_traded` and `trades_count`. These two variables are strongly positively correlated (ρ = .832), meaning that the larger the volume traded is, the more trades have been taken place, which is logical. Next, I calculated the Pearson test between the remaining two pairs. It turned out that while the there is some positive correlation between `volume_traded` and `price_close` (ρ = .443), there is no correlation between `trades_count` and `price_close` (ρ = .019). This means that the higher the Bitcoin price is, the more is the volume traded, however, it does not mean that more trades have occurred.\n",
    "\n",
    "For the last question, I got another dataset from John Hopkins University's Covid tracking website (via GitHub). The dataset contains cumulative daily cases for different countries and regions from January 22, 2020, up till now. However, I only need the total number of cases per day, and only the data for 2020, so I created a smaller dataframe with only the combined Covid cases per day. Then I added another column, that had the daily new cases. I plotted both the Bitcoin price and the daily cumulative Covid cases on the same chart but with different scales. It could be seen visually on the chart that the two variables are positively correlated. I did a Pearson correlation test and found out that there is, indeed, a strong positive correlation between them (ρ = .924). I did the same with Bitcoin price and daily new Covid cases, and again found out that the two are positively correlated (ρ = .840). However, correlation does not mean causation.\n",
    "\n",
    "All in all, I found that the Bitcoin price time series is non-stationary, that `volume_traded` is positively correlated with `trades_count` and `price_close`, and that the number of Covid cases (both new and cumulative) and the Bitcoin price are correlated. Again, the analysis was done on the 2020 Bitcoin price data taken from Binance. Also, there might have been a bunch of other factors that affected the Bitcoin price."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e37895af",
   "metadata": {},
   "source": [
    "## Q0: Difference Between Consecutive Weeks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4450522b",
   "metadata": {},
   "source": [
    "How can I find an answer to this question? Can I use t-tests ona time series (values are dependent)?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e31c1fc1",
   "metadata": {},
   "source": [
    "First, I'll divide the data into weeks. To do that, I create a new column in the dataframe, called `week`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9392c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add new column by binning\n",
    "df['week'] = pd.cut(df.time_open.dt.dayofyear, bins=range(0, 373, 7), labels=range(1, 54))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0b6e80a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Check how many entries every week has\n",
    "df.week.value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5ebda78",
   "metadata": {},
   "source": [
    "I will now plot a bar graph, to see the mean price for each week."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7047e31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Barplot for average close price per week\n",
    "ax = sns.barplot(x=\"week\", y=\"price_close\", data=df, palette = ['#748B75'])\n",
    "\n",
    "# Some x tick labels are too long, so, I need to wrap the title\n",
    "# Get the x tick labels\n",
    "ax.get_xticklabels()\n",
    "\n",
    "# Get the text out\n",
    "texts = [t.get_text()  for t in ax.get_xticklabels()]\n",
    "\n",
    "# Wrap the text\n",
    "texts = [textwrap.fill(t.get_text(), 12)  for t in ax.get_xticklabels()]\n",
    "\n",
    "# Set the new wrapped titles\n",
    "ax.set_xticklabels([textwrap.fill(t.get_text(), 12)  for t in ax.get_xticklabels()])\n",
    "\n",
    "\n",
    "# Set y-axis label\n",
    "ax.set_ylabel(\"Price ($)\")\n",
    "\n",
    "# Set x-axis label\n",
    "ax.set_xlabel(\"Week\")\n",
    "\n",
    "# Title\n",
    "ax.set_title(\"Average Price Per Week\")\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b39e9240",
   "metadata": {},
   "source": [
    "I will save the dataframe, so that I don't have to get it using the API again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83ae5ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the dataframe to a csv file\n",
    "df.to_csv(\"BTCUSDT_2020.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0d7a969",
   "metadata": {},
   "source": [
    "Now, I will conduct t-tests for the price data for each two consecutive weeks. I will also plot the pricelines. First, I define a plotting function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07febd4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_priceline(start_week, end_week, pvalue):\n",
    "    \"\"\"\n",
    "    Plots the priceline for the given interval (in weeks).\n",
    "    \n",
    "    Keyword parameters:\n",
    "        start_week - the start of the interval.\n",
    "        \n",
    "        end_week   - the end of the interval.\n",
    "        \n",
    "        pvalue     - the pvalue of the t-test for the given two weeks.    \n",
    "    \"\"\"\n",
    "    # Priceline\n",
    "    ax = sns.lineplot(x=\"time_open\", y=\"price_close\", data=df, color='#748B75' if pvalue < 0.05 else '#EE2E31')\n",
    "    # Set y-axis label\n",
    "    ax.set_ylabel(\"Price ($)\")\n",
    "\n",
    "    # Set x-axis label\n",
    "    ax.set_xlabel(\"Date\")\n",
    "\n",
    "    df_weeks = df[(week <= df.week) & (df.week <= week+1)]\n",
    "    \n",
    "    # Set x limits\n",
    "    limits = list(df_weeks.time_open)\n",
    "    ax.set_xlim(limits[0], limits[-1])\n",
    "    \n",
    "    # Set y limits\n",
    "    ax.set_ylim(df_weeks.price_close.min()*.95, df_weeks.price_close.max()*1.05)\n",
    "\n",
    "    # Title\n",
    "    ax.set_title(f\"BTC Price Over Time | Weeks {week}-{week+1} | p-value: {pvalue:.5f}\")\n",
    "\n",
    "    # Show the plot\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43f7d8bf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# For each two consecutive weeks, conduct a t-test\n",
    "for week in range(1, 53):\n",
    "    prev_week = df[(df.week == week)].price_close\n",
    "    next_week = df[(df.week == week + 1)].price_close\n",
    "\n",
    "    res = stats.ttest_ind(prev_week, next_week)\n",
    "    \n",
    "    plot_priceline(week, week+1, res.pvalue)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40842209",
   "metadata": {},
   "source": [
    "Almost every t-test returned a small enough p-value, which means there is significant evidence to reject the Null hypothesis and accept that there is dependence between date (time) and price. Since this is a timeseries and each value is dependent on the previous price, this is logical. Also, many other factors affect the price at different points of time, meaning there is dependance between time and price."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
